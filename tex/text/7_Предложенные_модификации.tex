\chapter{Предложенные модификации}
\label{ch:modifications}

В рамках исследования влияния дополнительной информации на качество работы Re-Id моделей рассматривается классическая постановка задачи $-$ ре-идентификация людей. В данном случае возможно воспользоваться публичными датасетами и бенчмарками для сравнения качества, а также существующей дополнительной разметкой к ним. Рассматривается дополнительная информация двух типов.


\section{Семантические атрибуты}

Во-первых, рассматривается разметка данных по семантическим атрибутам. Работа \cite{lin2019improving} предоставляет разметку Market-1501\_Attribute для датасета Market-1501 \cite{zheng2015scalable} по таким категориям, как: пол, возраст длина волос, тип, длина и цвет верхней и нижней частей одежды, наличие сумок и рюкзаков и др. Описания категорий приведены в \hyperref[tab:market_attributes]{Таблице \ref*{tab:market_attributes}}

\begin{table}[]
	\centering
	\caption{Категории семантических атрибутов в Market-1501\_Attribute}
	\begin{tabular}{|l|l|l|}
		\hline
		\multicolumn{1}{|l|}{Признак} & \multicolumn{1}{l|}{Количество значений} & 
		\multicolumn{1}{l|}{Значения}\\ \hline
		Пол & 2 & мужской, женский \\ \hline
		Длина волос & 2 & короткие, длинные \\ \hline
		Длина рукава & 2 & длинные, короткие \\ \hline
		Длина нижней & 2 & длинная, короткая \\
		части одежды & & \\ \hline
		Тип нижней & 2 & брюки, юбка \\
		части одежды & & \\ \hline
		Наличие головного & 2 & нет, есть \\
		убора & & \\ \hline
		Наличие рюкзака & 2 & нет, есть \\ \hline
		Наличие сумки & 2 & нет, есть \\ \hline
		Наличие дамской & 2 & нет, есть \\
		сумки & & \\ \hline
		Возраст & 4 & подросток, молодой \\
		& & взрослый, старый \\ \hline
		Цвет верхней & 8 & черный, белый \\
		части одежды & & красный, фиолетовый \\
		& & желтый, серый \\
		& & синий, зеленый \\ \hline
		Цвет нижней & 9 & черный, белый \\
		части одежды & & розовый, фиолетовый \\
		& & желтый, серый \\
		& & синий, зеленый \\
		& & коричневый \\ \hline
	\end{tabular}
	\label{tab:market_attributes}
\end{table}

\subsection{Составление промптов на основе атрибутов}

Модель CLIP-ReID опирается на свойство соответствия обучаемых визуальных представлений обучаемым текстовым представлениям. Благодаря двухстадийному обучению удается сохранить заложенную в мультимодальную модель CLIP информацию и использовать ее для регуляризации и улучшения состоятельности эмбеддингов.

В случае же наличия разметки по семантическим атрибутам возможно построение текстовых описаний напрямую. Таким образом, вместо обучаемых промптов возможно составление описаний вида "A photo of a teenager girl with long hair wearing a red T-shirt and gray shorts  carrying a backpack"\ или "A photo of an adult man with short hair wearing a gray T-shirt and black shorts".

Таким образом, первая стадия CLIP-ReID опускается; на второй стадии составляются текстовые эмбеддинги из фиксированных описаний.

\subsection{Label smoothing на основе атрибутов на первой стадии}

В данном варианте рассматривается внесение изменений в функцию потерь первой стадии обучения (\hyperref[eq:Lt2i]{Формула \ref*{eq:Lt2i}}). Для учета информации о похожести людей, имеющих совпадающие значения некоторых атрибутов, предлагается добавление к маске соответствия ID человека маски соответствия атрибутов.

\begin{equation}
	\mathcal L_{t2i}(i) = \frac{1}{|P(y_i)|} \sum \limits_{k = 1}^B -q_k \log \frac{\exp \left( s(V_k, T_i) \right)}{\sum_{j = 1}^B \exp \left( s(V_j, T_i) \right)}.
\end{equation}

Здесь $q_k = (1 - \lambda)\delta_{ik} + \lambda m_{ik}$, где $m_{ik}$ есть доля совпадающих значений атрибутов, $\lambda$ - гиперпараметр.

\subsection{Label smoothing на основе атрибутов на обеих стадиях}

Также возможно расширение этого метода на все этапы обучения. На второй стадии вводятся изменения в правила применения label smoothing. Так, в \hyperref[eq:Lid]{Формуле \ref*{eq:Lid}} и \hyperref[eq:Li2tce]{Формуле \ref*{eq:Li2tce}} коэффициенты кросс-энтропии $q_k$ будут выражаться как $q_k = (1 - \lambda)\delta_{ik} + \lambda m_{ik}$. 

В \hyperref[eq:Ltri]{Формуле \ref*{eq:Ltri}} расстояния до негативных примеров корректируются пропорционально маске сответствия атрибутов:

\begin{equation}
	\mathcal L_{tri} (i) = \max \left( d_p - m_{in} \cdot d_n + \rho, 0 \right).
\end{equation}

Таким образом, при подборе ближайшего негативного примера с помощью hard-batch triplet mining будет увеличиваться приоритет тех объектов, соответствие атрибутов с которыми меньше.


\section{Ключевые точки}

Другой тип рассматриваемой дополнительной информации $-$ разметка изображений людей по ключевым точкам согласно задаче оценки позы, или \textit{pose estimation}. В одном из стандартных вариантов такая разметка содержит 17 ключевых точек, соответствующих лицу, частям тела и суставам.

\subsection{Обучаемый энкодер ключевых точек}

В данном варианте рассматривается использование предразметки ключевых точек для изображений датасета Market-1501, полученное с помощью метода, основанного на HRNet \cite{sun2019deep} $-$ state-of-the-art модели pose estimation. Для обработки данной разметки добавляется отдельный обучаемый энкодер, состоящий из четырех полносвязных слоев. 

Таким образом, на выходе модели имеется три эмбеддинга: текстовый, визуальный и ключевых точек. Последний применяется в качестве регуляризатора для визаульного эмбеддинга. А именно, перед проекцией в общее CLIP-пространство эмбеддинги изображения и ключевых точек конкатенируются. После этого линейный слой отображает их в общее пространство.

\subsection{Регуляризация эмбеддингом модели pose estimation}

Другой вариант использования эмбеддинга ключевых точек $-$ включение эмбеддинга модели pose estimation напрямую перед этап проекции в общее пространство. Таким образом, есть возможность использовать более информативное представление, извлекаемое напрямую из изображения, чем с помощью обучаемого энкодера разметки.

К сожалению, использовать этот эмбеддинг в CLIP-режиме, то есть строя соответствие между тремя, а не двумя, типами эмбеддингов, является более сложной задачей. Действительно, для наделения экнодера ключевых точек таким свойством соответствия нужно более глубоко повторять процесс обучения модели CLIP; в противном случае свойством соответствия в энкодер pose estimation не закладывается. Поэтому в данной работе рассматривается вариант с регуляризацией в виде конкатенации.

